# Base Configuration for TrainCW
# This is a sample configuration file for training Morse code neural networks

# Model Architecture
model:
  name: "cnn_lstm_ctc"

  # CNN Encoder
  encoder:
    num_conv_layers: 3
    conv_channels: [32, 64, 128]
    kernel_sizes: [[3, 3], [3, 3], [3, 3]]
    pool_sizes: [[2, 2], [2, 2], [2, 2]]
    dropout: 0.2

  # LSTM Layers
  lstm:
    hidden_size: 256
    num_layers: 2
    bidirectional: true
    dropout: 0.3

  # Output Layer
  output:
    num_characters: 40  # A-Z, 0-9, space, special chars

# Audio Processing
audio:
  sample_rate: 16000  # Hz
  window_length: 0.025  # 25ms
  hop_length: 0.010  # 10ms
  n_fft: 512
  n_mels: 64
  fmin: 0
  fmax: 8000

# Data Generation
data:
  # Training data
  train:
    samples_per_epoch: 10000
    batch_size: 32
    num_workers: 4
    pin_memory: true

  # Validation data
  val:
    samples: 1000
    batch_size: 64

  # Text generation
  text:
    min_length: 5
    max_length: 50
    distributions:
      random_chars: 0.40
      words: 0.30
      callsigns: 0.20
      abbreviations: 0.10

  # Morse code parameters
  morse:
    wpm_range: [5, 40]
    wpm_distribution: "beta"  # Favor 15-25 WPM
    frequency_range: [400, 900]  # Hz
    dit_dah_ratio_range: [2.5, 3.5]  # Ideal is 3.0
    timing_variance: 0.20  # ±20%

  # Audio synthesis
  synthesis:
    envelope:
      rise_time_range: [0.001, 0.010]  # 1-10ms
      fall_time_range: [0.001, 0.010]
    frequency_drift: 0.05  # Max ±5% drift
    chirp_probability: 0.1

  # Noise and interference
  noise:
    snr_range: [-5, 25]  # dB
    types:
      white_noise: 0.4
      pink_noise: 0.3
      qrm: 0.2  # Other CW signals
      qrn: 0.1  # Atmospheric noise

    qrm:  # Interference from other CW
      probability: 0.3
      frequency_offset_range: [100, 500]  # Hz
      strength_range: [0.2, 0.8]

    qrn:  # Atmospheric noise
      probability: 0.2
      impulse_rate: 0.1  # Impulses per second

    fading:
      probability: 0.2
      rate_range: [0.1, 1.0]  # Hz
      depth_range: [0.2, 0.6]

# Training
training:
  epochs: 100
  optimizer:
    name: "adam"
    learning_rate: 0.001
    weight_decay: 0.00001

  scheduler:
    name: "reduce_on_plateau"
    patience: 5
    factor: 0.5
    min_lr: 0.00001

  loss:
    name: "ctc"
    blank_idx: 0
    reduction: "mean"

  # Curriculum learning
  curriculum:
    enabled: true
    phases:
      - name: "easy"
        epochs: 20
        snr_min: 15
        wpm_range: [15, 25]
        timing_variance: 0.10

      - name: "medium"
        epochs: 30
        snr_min: 5
        wpm_range: [10, 35]
        timing_variance: 0.20

      - name: "hard"
        epochs: 50
        snr_min: -5
        wpm_range: [5, 40]
        timing_variance: 0.30

  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001

  # Checkpointing
  checkpoints:
    save_dir: "checkpoints"
    save_best: true
    save_last: true
    save_frequency: 5  # Save every N epochs

# Evaluation
evaluation:
  metrics:
    - "cer"  # Character Error Rate
    - "wer"  # Word Error Rate

  # Test on different conditions
  test_conditions:
    by_speed: [5, 10, 15, 20, 25, 30, 35, 40]  # WPM
    by_snr: [-5, 0, 5, 10, 15, 20, 25]  # dB
    by_noise_type: ["clean", "white", "qrm", "qrn", "fading"]

# Logging
logging:
  level: "INFO"
  tensorboard: true
  log_dir: "logs"
  log_interval: 10  # Log every N batches

# Export
export:
  formats: ["onnx", "coreml"]
  quantization: "float16"  # For iOS optimization
  target_device: "ios"

# Random seed for reproducibility
seed: 42
